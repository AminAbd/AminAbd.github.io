---
layout: post
title: "Step-by-Step Guide to Setting Up and Using Databricks for Big Data Analysis"
date: 2024-11-25
author: "Ameen Abdelmutalab"
tags: [big data, Databricks, Spark, data science]
image: "/assets/img/Databricks.png"
categories: Spark
---

## Introduction

Databricks is a comprehensive platform for big data processing and machine learning. This guide walks you through setting up and using Databricks Community Edition step by step, with corresponding screenshots for clarity.



## Step 1: The Databricks Home Page

After logging in, you’ll land on the Databricks home page. This dashboard offers quick access to key features like **Import and Transform Data** and **Create Notebook**. You can also navigate using the sidebar on the left.

![Databricks Home Page](/assets/img/DataBricks/Databricks1.png)

Click **Create Table** or **Create Notebook** to get started, or explore the sidebar for additional tools.
---

## Step 2: Exploring the "New" Menu

On the left-hand sidebar, click the **New** button to access the dropdown menu. This menu allows you to create various resources such as:

- **Notebook**: For executing code.
- **Table**: To manage datasets.
- **Cluster**: To run your computations.
- **Experiment**: To conduct machine learning experiments.

![Databricks New Menu](/assets/img/Databricks.png)

For this tutorial, we’ll focus on creating a cluster in the next step.

---
## Step 3: Configuring a Cluster

Clusters are necessary for running Databricks notebooks. To create a cluster:

1. Select **New > Cluster**.
2. Name your cluster (e.g., "Ameen1 Cluster").
3. Select the **Databricks runtime version** based on your requirements. Machine learning runtimes (e.g., `15.4 LTS ML`) are great for advanced workflows.

![Creating a Cluster](/assets/img/Databricks.png)

Once configured, start the cluster to make it available for computations.

---
## Step 4: Importing a Notebook

To use pre-built resources, import a notebook into Databricks:

1. Go to the **Workspace** section on the left sidebar.
2. Click the three-dot menu in your folder and select **Import**.
3. In the import dialog, choose the **URL** option and paste the link to the notebook file you want to load.

![Importing a Notebook](/assets/img/Databricks.png)

---

## Step 5: Choosing the Notebook Link to Import

Once the import dialog is open, paste the URL of the notebook you want to use. For instance:

https://files.training.databricks.com/courses/ucdavis/Lessons.dbc


Click **Import** to add the notebook to your workspace.

![Choosing the Notebook Link](/assets/img/Databricks.png)

This will load all the files and folders associated with the notebook into your workspace.

---

## Step 6: Opening the Imported Folder

After importing, navigate to the folder in your workspace. The imported folder will contain subfolders and files relevant to your course or project.

![Opening the Imported Folder](/assets/img/Databricks.png)

Browse the folder to familiarize yourself with the contents.

---

## Step 7: Creating a New Notebook

To create a new notebook:

1. Go to the workspace and click **New > Notebook**.
2. Provide a name for your notebook and choose a default language (e.g., Python, SQL, or Scala).

![Creating a New Notebook](/assets/img/Databricks.png)

This new notebook can be used for exploring the imported files or writing your custom scripts.

---

## Step 8: Writing and Executing Code in Your Notebook

Open the newly created notebook and start writing code. You can switch between multiple programming languages like Python, SQL, or Scala. For example:

### Running SQL Queries:
```sql
%sql
SHOW TABLES
```
Running Python Code:
```python
%python
x = 1
print(x)
```
The notebook interface provides real-time feedback, displaying the results right below each cell.
![Creating a New Notebook](/assets/img/Databricks.png)


